"use strict";(self.webpackChunkdevops_sandbox=self.webpackChunkdevops_sandbox||[]).push([[1198],{6148:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"db/kafka/strimzi","title":"Strimzi Kafka Operator","description":"|Distro|Strimzi Kafka Operator|","source":"@site/docs/db/kafka/strimzi.md","sourceDirName":"db/kafka","slug":"/db/kafka/strimzi","permalink":"/docs/db/kafka/strimzi","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"distro","permalink":"/docs/tags/distro"},{"inline":true,"label":"strimzi","permalink":"/docs/tags/strimzi"},{"inline":true,"label":"kafka","permalink":"/docs/tags/kafka"},{"inline":true,"label":"database","permalink":"/docs/tags/database"}],"version":"current","frontMatter":{"tags":["distro","strimzi","kafka","database"]},"sidebar":"tutorialSidebar","previous":{"title":"Apache Kafka","permalink":"/docs/db/kafka/"},"next":{"title":"MongoDB","permalink":"/docs/db/mongodb/"}}');var t=a(4848),s=a(8453);const o={tags:["distro","strimzi","kafka","database"]},i="Strimzi Kafka Operator",c={},l=[{value:"Setup",id:"setup",level:2},{value:"Usecases",id:"usecases",level:2},{value:"\u2705 Basic: create cluster, create user, create topic, connect",id:"white_check_mark-basic-create-cluster-create-user-create-topic-connect",level:3},{value:"\ud83d\udd04 Common: produce message to topic, consume from topic, consumer group",id:"arrows_counterclockwise-common-produce-message-to-topic-consume-from-topic-consumer-group",level:3},{value:"Advanced: replication, etc.",id:"advanced-replication-etc",level:3},{value:"\u2705 Monitoring",id:"white_check_mark-monitoring",level:2},{value:"Maintenence",id:"maintenence",level:2},{value:"Articles",id:"articles",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"strimzi-kafka-operator",children:"Strimzi Kafka Operator"})}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:(0,t.jsx)(n.strong,{children:"Distro"})}),(0,t.jsx)(n.th,{children:(0,t.jsx)(n.a,{href:"https://github.com/strimzi/strimzi-kafka-operator",children:"Strimzi Kafka Operator"})})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Type"})}),(0,t.jsx)(n.td,{children:"kubernetes-operator"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Deploy"})}),(0,t.jsx)(n.td,{children:"helm-chart"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Docs"})}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.a,{href:"https://strimzi.io/documentation/",children:"link"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Backup"})}),(0,t.jsx)(n.td,{})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Scaling"})}),(0,t.jsx)(n.td,{})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"CLI"})}),(0,t.jsx)(n.td,{children:"kafkacat"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"UI"})}),(0,t.jsxs)(n.td,{children:[(0,t.jsx)(n.a,{href:"https://github.com/provectus/kafka-ui",children:"kafka-ui"})," (web)"]})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsx)(n.p,{children:"Run on default configuration"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Kafka Bridge"})," provides a RESTful interface that allows HTTP-based clients to interact with a Kafka cluster."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Mirror Maker"})," is a tool for replicating data between Kafka clusters, which can be useful for disaster recovery or data migration."]}),"\n",(0,t.jsx)(n.h2,{id:"usecases",children:"Usecases"}),"\n",(0,t.jsxs)(n.h3,{id:"white_check_mark-basic-create-cluster-create-user-create-topic-connect",children:["\u2705"," Basic: create cluster, create user, create topic, connect"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Single-node cluster configuration"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["use ",(0,t.jsx)(n.code,{children:"KafkaNodePool"})," to create zookeeper-less cluster with KRaft mode enabled"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaNodePool\nmetadata:\n  name: single-node\n  labels:\n    strimzi.io/cluster: kafka-cluster\nspec:\n  replicas: 1\n  roles:\n    - controller\n    - broker\n  storage:\n    type: jbod\n    volumes:\n      - id: 0\n        type: persistent-claim\n        size: 2Gi\n        deleteClaim: true\n        kraftMetadata: shared\n"})}),"\n",(0,t.jsx)(n.p,{children:"Kafka cluster configuration, pay attention to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:".spec.kafka.listeners"})," -- defines the listeners for the Kafka cluster, including authentication methods."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:".spec.kafka.authorization"})," -- defines the authorization type and super users."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"apiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n  name: kafka-cluster\n  annotations:\n    strimzi.io/node-pools: enabled\n    strimzi.io/kraft: enabled\nspec:\n  kafka:\n    version: 4.0.0\n    metadataVersion: 4.0-IV3\n    authorization:\n      type: simple\n      superUsers:\n        - admin-kafka-user\n    listeners:\n      - name: plain # need to stay without auth for proper broker communication\n        port: 9092\n        type: internal\n        tls: false\n      - name: internal # add port to main brokers service with scram-sha-512 auth\n        port: 9095\n        type: internal\n        tls: false\n        authentication:\n          type: scram-sha-512\n      - name: tls\n        port: 9093\n        type: internal\n        tls: true\n      - name: portforward  # special service configured to be used with port-forward\n        port: 9094\n        type: nodeport\n        tls: false\n        authentication:\n          type: scram-sha-512\n        configuration:\n          bootstrap:\n            nodePort: 30094\n          brokers:\n          - broker: 0\n            nodePort: 30664\n            advertisedHost: localhost\n    config:\n      offsets.topic.replication.factor: 1\n      transaction.state.log.replication.factor: 1\n      transaction.state.log.min.isr: 1\n      default.replication.factor: 1\n      min.insync.replicas: 1\n      auto.create.topics.enable: false\n      delete.topic.enable: true\n  entityOperator:\n    topicOperator: {}\n    userOperator: {}\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Topic"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"apiVersion: kafka.strimzi.io/v1beta1\nkind: KafkaTopic\nmetadata:\n  name: dante-topic\n  namespace: kafka\n  labels:\n    strimzi.io/cluster: kafka-cluster\nspec:\n  partitions: 10\n  replicas: 1\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Users"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["admin user list in ",(0,t.jsx)(n.code,{children:"Kafka"})," resource ",(0,t.jsx)(n.code,{children:".spec.kafka.authorization.superUsers"})]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"apiVersion: kafka.strimzi.io/v1beta1\nkind: KafkaUser\nmetadata:\n  name: admin-kafka-user\n  namespace: kafka\n  labels:\n    strimzi.io/cluster: kafka-cluster\nspec:\n  authentication:\n    type: scram-sha-512\n"})}),"\n",(0,t.jsxs)(n.p,{children:["user with access to ",(0,t.jsx)(n.code,{children:"topic`` and "}),"consumer group`"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'apiVersion: kafka.strimzi.io/v1beta1\nkind: KafkaUser\nmetadata:\n  name: dante-kafka-user\n  namespace: kafka\n  labels:\n    strimzi.io/cluster: kafka-cluster\nspec:\n  authentication:\n    type: scram-sha-512\n  authorization:\n    type: simple\n    acls:\n    - resource:\n        type: topic\n        name: dante-topic\n      operations:\n        - Describe\n        - Read\n        - Write\n      host: "*"\n    - resource:\n        type: group\n        name: dante-group\n        patternType: prefix\n      operations:\n        - Describe\n        - Read\n      host: "*"\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Produce and Consume messages internally"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["our users need scram-sha-512 auth, so we can use only internal listener with ",(0,t.jsx)(n.code,{children:"scram-sha-512"})," authentication enabled (on 9095 port)"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# create properties files with scram-sha-512 creds\nfor user in dante-kafka-user admin-kafka-user; do\n  cat <<EOF | kubectl exec -i kafka-cluster-single-node-0 -n kafka -c kafka -- sh -c 'cat > /tmp/'${user}'.properties'\nsecurity.protocol=SASL_PLAINTEXT\nsasl.mechanism=SCRAM-SHA-512\nsasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username=\"$user\" password=\"$(kubectl get secret $user -n kafka -o jsonpath='{.data.password}' | base64 -d)\";\nEOF\ndone\n\n# produce message as dante\n./bin/kafka-console-producer.sh \\\n  --bootstrap-server kafka-cluster-kafka-bootstrap:9095 \\\n  --producer.config /tmp/dante-kafka-user.properties \\\n  --topic dante-topic\n>Hello\n\n# produce message as admin\n./bin/kafka-console-producer.sh \\\n  --bootstrap-server kafka-cluster-kafka-bootstrap:9095 \\\n  --producer.config /tmp/admin-kafka-user.properties \\\n  --topic dante-topic\n>world\n\n# consume as admin\n./bin/kafka-console-consumer.sh \\\n  --bootstrap-server kafka-cluster-kafka-bootstrap:9095 \\\n  --producer.config /tmp/dante-kafka-user.properties \\\n  --topic dante-topic --from-beginning\nHello\nworld\n^CProcessed a total of 2 messages\n\n# consume as dante\n./bin/kafka-console-consumer.sh \\\n  --bootstrap-server kafka-cluster-kafka-bootstrap:9095 \\\n  --producer.config /tmp/dante-kafka-user.properties \\\n  --topic dante-topic --from-beginning\nHello\nworld\n^CProcessed a total of 2 messages\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Access Kafka cluster via ",(0,t.jsx)(n.code,{children:"port-forward"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"port-forwarding listener explained:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"      - name: portforward  # special service configured to be used with port-forward\n        port: 9094\n        type: nodeport\n        tls: false\n        authentication:\n          type: scram-sha-512\n        configuration:\n          bootstrap:\n            nodePort: 30094\n          brokers:\n          - broker: 0\n            nodePort: 30664 # each brokers port have to be port-forwarded\n            advertisedHost: localhost # because afer port-forwarding we will access it via localhost\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'kubectl --context kind-homelab port-forward svc/kafka-cluster-single-node-portforward-0 30664:9094 -n kafka\nkubectl --context kind-homelab port-forward svc/kafka-cluster-kafka-portforward-bootstrap 9094:9094 -n kafka\n\nkcat -b localhost:9094 \\\n  -X security.protocol=SASL_PLAINTEXT \\\n  -X sasl.mechanism=SCRAM-SHA-512 \\\n  -X sasl.username=dante-kafka-user \\\n  -X sasl.password=qBD7sXygrJWuAfAZls8Uyr4qo26wPI9k \\\n  -L\nMetadata for all topics (from broker 0: sasl_plaintext://localhost:30664/0):\n 1 brokers:\n  broker 0 at localhost:30664 (controller)\n 1 topics:\n  topic "dante-topic" with 10 partitions:\n    partition 0, leader 0, replicas: 0, isrs: 0\n    partition 1, leader 0, replicas: 0, isrs: 0\n    partition 2, leader 0, replicas: 0, isrs: 0\n    partition 3, leader 0, replicas: 0, isrs: 0\n    partition 4, leader 0, replicas: 0, isrs: 0\n    partition 5, leader 0, replicas: 0, isrs: 0\n    partition 6, leader 0, replicas: 0, isrs: 0\n    partition 7, leader 0, replicas: 0, isrs: 0\n    partition 8, leader 0, replicas: 0, isrs: 0\n    partition 9, leader 0, replicas: 0, isrs: 0\n'})}),"\n",(0,t.jsxs)(n.h3,{id:"arrows_counterclockwise-common-produce-message-to-topic-consume-from-topic-consumer-group",children:["\ud83d\udd04"," Common: produce message to topic, consume from topic, consumer group"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'$  echo "Hello from kcat" | kcat -b localhost:9094 \\\n  -X security.protocol=SASL_PLAINTEXT \\\n  -X sasl.mechanism=SCRAM-SHA-512 \\\n  -X sasl.username=dante-kafka-user \\\n  -X sasl.password=qBD7sXygrJWuAfAZls8Uyr4qo26wPI9k \\\n  -P -t dante-topic\n\n$  kcat -b localhost:9094 \\\n  -X security.protocol=SASL_PLAINTEXT \\\n  -X sasl.mechanism=SCRAM-SHA-512 \\\n  -X sasl.username=dante-kafka-user \\\n  -X sasl.password=qBD7sXygrJWuAfAZls8Uyr4qo26wPI9k \\\n  -C -t dante-topic -o beginning\n% Reached end of topic dante-topic [0] at offset 0\nworld\nHello from kcat\n% Reached end of topic dante-topic [3] at offset 0\nnew world1\n% Reached end of topic dante-topic [5] at offset 0\n% Reached end of topic dante-topic [6] at offset 0\nnew hello1\nHello\n% Reached end of topic dante-topic [9] at offset 0\n% Reached end of topic dante-topic [1] at offset 1\n% Reached end of topic dante-topic [2] at offset 1\n% Reached end of topic dante-topic [4] at offset 1\n% Reached end of topic dante-topic [7] at offset 1\n% Reached end of topic dante-topic [8] at offset 1\n^C\n'})}),"\n",(0,t.jsx)(n.h3,{id:"advanced-replication-etc",children:"Advanced: replication, etc."}),"\n",(0,t.jsxs)(n.h2,{id:"white_check_mark-monitoring",children:["\u2705"," Monitoring"]}),"\n",(0,t.jsx)(n.admonition,{title:"Official example",type:"note",children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/strimzi/strimzi-kafka-operator/blob/main/packaging/examples/metrics/kafka-metrics.yaml",children:"https://github.com/strimzi/strimzi-kafka-operator/blob/main/packaging/examples/metrics/kafka-metrics.yaml"})})}),"\n",(0,t.jsxs)(n.admonition,{title:"Grafana Dashboards",type:"note",children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/strimzi/strimzi-kafka-operator/tree/main/packaging/examples/metrics/grafana-dashboards",children:"https://github.com/strimzi/strimzi-kafka-operator/tree/main/packaging/examples/metrics/grafana-dashboards"})}),(0,t.jsx)(n.p,{children:"Can be enabled in values:"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"strimzi-kafka-operator:\n  dashboards:\n    enabled: true\n    namespace: kafka\n"})})]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["add ",(0,t.jsx)(n.code,{children:"ConfigMap"})," with metrics"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/strimzi/strimzi-kafka-operator/blob/main/packaging/examples/metrics/kafka-metrics.yaml",children:"Source"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'kind: ConfigMap\napiVersion: v1\nmetadata:\n  name: kafka-metrics\n  labels:\n    app: strimzi\ndata:\n  kafka-metrics-config.yml: |\n    # See https://github.com/prometheus/jmx_exporter for more info about JMX Prometheus Exporter metrics\n    lowercaseOutputName: true\n    rules:\n    # Special cases and very specific rules\n    - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value\n      name: kafka_server_$1_$2\n      type: GAUGE\n      labels:\n        clientId: "$3"\n        topic: "$4"\n        partition: "$5"\n    - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value\n      name: kafka_server_$1_$2\n      type: GAUGE\n      labels:\n        clientId: "$3"\n        broker: "$4:$5"\n    - pattern: kafka.server<type=(.+), cipher=(.+), protocol=(.+), listener=(.+), networkProcessor=(.+)><>connections\n      name: kafka_server_$1_connections_tls_info\n      type: GAUGE\n      labels:\n        cipher: "$2"\n        protocol: "$3"\n        listener: "$4"\n        networkProcessor: "$5"\n    - pattern: kafka.server<type=(.+), clientSoftwareName=(.+), clientSoftwareVersion=(.+), listener=(.+), networkProcessor=(.+)><>connections\n      name: kafka_server_$1_connections_software\n      type: GAUGE\n      labels:\n        clientSoftwareName: "$2"\n        clientSoftwareVersion: "$3"\n        listener: "$4"\n        networkProcessor: "$5"\n    - pattern: "kafka.server<type=(.+), listener=(.+), networkProcessor=(.+)><>(.+-total):"\n      name: kafka_server_$1_$4\n      type: COUNTER\n      labels:\n        listener: "$2"\n        networkProcessor: "$3"\n    - pattern: "kafka.server<type=(.+), listener=(.+), networkProcessor=(.+)><>(.+):"\n      name: kafka_server_$1_$4\n      type: GAUGE\n      labels:\n        listener: "$2"\n        networkProcessor: "$3"\n    - pattern: kafka.server<type=(.+), listener=(.+), networkProcessor=(.+)><>(.+-total)\n      name: kafka_server_$1_$4\n      type: COUNTER\n      labels:\n        listener: "$2"\n        networkProcessor: "$3"\n    - pattern: kafka.server<type=(.+), listener=(.+), networkProcessor=(.+)><>(.+)\n      name: kafka_server_$1_$4\n      type: GAUGE\n      labels:\n        listener: "$2"\n        networkProcessor: "$3"\n    # Some percent metrics use MeanRate attribute\n    # Ex) kafka.server<type=(KafkaRequestHandlerPool), name=(RequestHandlerAvgIdlePercent)><>MeanRate\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+)Percent\\w*><>MeanRate\n      name: kafka_$1_$2_$3_percent\n      type: GAUGE\n    # Generic gauges for percents\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+)Percent\\w*><>Value\n      name: kafka_$1_$2_$3_percent\n      type: GAUGE\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+)Percent\\w*, (.+)=(.+)><>Value\n      name: kafka_$1_$2_$3_percent\n      type: GAUGE\n      labels:\n        "$4": "$5"\n    # Generic per-second counters with 0-2 key/value pairs\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+)PerSec\\w*, (.+)=(.+), (.+)=(.+)><>Count\n      name: kafka_$1_$2_$3_total\n      type: COUNTER\n      labels:\n        "$4": "$5"\n        "$6": "$7"\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+)PerSec\\w*, (.+)=(.+)><>Count\n      name: kafka_$1_$2_$3_total\n      type: COUNTER\n      labels:\n        "$4": "$5"\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+)PerSec\\w*><>Count\n      name: kafka_$1_$2_$3_total\n      type: COUNTER\n    # Generic gauges with 0-2 key/value pairs\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>Value\n      name: kafka_$1_$2_$3\n      type: GAUGE\n      labels:\n        "$4": "$5"\n        "$6": "$7"\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+), (.+)=(.+)><>Value\n      name: kafka_$1_$2_$3\n      type: GAUGE\n      labels:\n        "$4": "$5"\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+)><>Value\n      name: kafka_$1_$2_$3\n      type: GAUGE\n    # Emulate Prometheus \'Summary\' metrics for the exported \'Histogram\'s.\n    # Note that these are missing the \'_sum\' metric!\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>Count\n      name: kafka_$1_$2_$3_count\n      type: COUNTER\n      labels:\n        "$4": "$5"\n        "$6": "$7"\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+), (.+)=(.*), (.+)=(.+)><>(\\d+)thPercentile\n      name: kafka_$1_$2_$3\n      type: GAUGE\n      labels:\n        "$4": "$5"\n        "$6": "$7"\n        quantile: "0.$8"\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+), (.+)=(.+)><>Count\n      name: kafka_$1_$2_$3_count\n      type: COUNTER\n      labels:\n        "$4": "$5"\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+), (.+)=(.*)><>(\\d+)thPercentile\n      name: kafka_$1_$2_$3\n      type: GAUGE\n      labels:\n        "$4": "$5"\n        quantile: "0.$6"\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+)><>Count\n      name: kafka_$1_$2_$3_count\n      type: COUNTER\n    - pattern: kafka.(\\w+)<type=(.+), name=(.+)><>(\\d+)thPercentile\n      name: kafka_$1_$2_$3\n      type: GAUGE\n      labels:\n        quantile: "0.$4"\n    # KRaft overall related metrics\n    # distinguish between always increasing COUNTER (total and max) and variable GAUGE (all others) metrics\n    - pattern: "kafka.server<type=raft-metrics><>(.+-total|.+-max):"\n      name: kafka_server_raftmetrics_$1\n      type: COUNTER\n    - pattern: "kafka.server<type=raft-metrics><>(current-state): (.+)"\n      name: kafka_server_raftmetrics_$1\n      value: 1\n      type: UNTYPED\n      labels:\n        $1: "$2"\n    - pattern: "kafka.server<type=raft-metrics><>(.+):"\n      name: kafka_server_raftmetrics_$1\n      type: GAUGE\n    # KRaft "low level" channels related metrics\n    # distinguish between always increasing COUNTER (total and max) and variable GAUGE (all others) metrics\n    - pattern: "kafka.server<type=raft-channel-metrics><>(.+-total|.+-max):"\n      name: kafka_server_raftchannelmetrics_$1\n      type: COUNTER\n    - pattern: "kafka.server<type=raft-channel-metrics><>(.+):"\n      name: kafka_server_raftchannelmetrics_$1\n      type: GAUGE\n    # Broker metrics related to fetching metadata topic records in KRaft mode\n    - pattern: "kafka.server<type=broker-metadata-metrics><>(.+):"\n      name: kafka_server_brokermetadatametrics_$1\n      type: GAUGE\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["enable metrics in ",(0,t.jsx)(n.code,{children:"Kafka"})," resource"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/strimzi/strimzi-kafka-operator/blob/main/packaging/examples/metrics/kafka-metrics.yaml",children:"Source"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'spec:\n  kafka:\n    metricsConfig:\n      type: jmxPrometheusExporter\n      valueFrom:\n        configMapKeyRef:\n          name: kafka-metrics\n          key: kafka-metrics-config.yml\n  kafkaExporter:\n    topicRegex: ".*"\n    groupRegex: ".*"\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"setup `PodMonitors``"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/strimzi/strimzi-kafka-operator/blob/main/packaging/examples/metrics/prometheus-install/strimzi-pod-monitor.yaml",children:"Source"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'apiVersion: monitoring.coreos.com/v1\nkind: PodMonitor\nmetadata:\n  name: cluster-operator-metrics\n  labels:\n    app: strimzi\nspec:\n  selector:\n    matchLabels:\n      strimzi.io/kind: cluster-operator\n  namespaceSelector:\n    matchNames:\n      - myproject\n  podMetricsEndpoints:\n  - path: /metrics\n    port: http\n---\napiVersion: monitoring.coreos.com/v1\nkind: PodMonitor\nmetadata:\n  name: entity-operator-metrics\n  labels:\n    app: strimzi\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: entity-operator\n  namespaceSelector:\n    matchNames:\n      - myproject\n  podMetricsEndpoints:\n  - path: /metrics\n    port: healthcheck\n---\napiVersion: monitoring.coreos.com/v1\nkind: PodMonitor\nmetadata:\n  name: bridge-metrics\n  labels:\n    app: strimzi\nspec:\n  selector:\n    matchLabels:\n      strimzi.io/kind: KafkaBridge\n  namespaceSelector:\n    matchNames:\n      - myproject\n  podMetricsEndpoints:\n  - path: /metrics\n    port: rest-api\n---\napiVersion: monitoring.coreos.com/v1\nkind: PodMonitor\nmetadata:\n  name: kafka-resources-metrics\n  labels:\n    app: strimzi\nspec:\n  selector:\n    matchExpressions:\n      - key: "strimzi.io/kind"\n        operator: In\n        values: ["Kafka", "KafkaConnect", "KafkaMirrorMaker2"]\n  namespaceSelector:\n    matchNames:\n      - myproject\n  podMetricsEndpoints:\n  - path: /metrics\n    port: tcp-prometheus\n    relabelings:\n    - separator: ;\n      regex: __meta_kubernetes_pod_label_(strimzi_io_.+)\n      replacement: $1\n      action: labelmap\n    - sourceLabels: [__meta_kubernetes_namespace]\n      separator: ;\n      regex: (.*)\n      targetLabel: namespace\n      replacement: $1\n      action: replace\n    - sourceLabels: [__meta_kubernetes_pod_name]\n      separator: ;\n      regex: (.*)\n      targetLabel: kubernetes_pod_name\n      replacement: $1\n      action: replace\n    - sourceLabels: [__meta_kubernetes_pod_node_name]\n      separator: ;\n      regex: (.*)\n      targetLabel: node_name\n      replacement: $1\n      action: replace\n    - sourceLabels: [__meta_kubernetes_pod_host_ip]\n      separator: ;\n      regex: (.*)\n      targetLabel: node_ip\n      replacement: $1\n      action: replace\n'})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["setup ",(0,t.jsx)(n.code,{children:"PrometheusRules"})," for alerting"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/strimzi/strimzi-kafka-operator/blob/main/packaging/examples/metrics/prometheus-install/prometheus-rules.yaml",children:"Source"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:"apiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  labels:\n    role: alert-rules\n    app: strimzi\n  name: prometheus-k8s-rules\nspec:\n  groups:\n  - name: kafka\n    rules:\n    - alert: KafkaRunningOutOfSpace\n      expr: kubelet_volume_stats_available_bytes{persistentvolumeclaim=~\"data(-[0-9]+)?-(.+)-kafka-[0-9]+\"} * 100 / kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=~\"data(-[0-9]+)?-(.+)-kafka-[0-9]+\"} < 15\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Kafka is running out of free disk space'\n        description: 'There are only {{ $value }} percent available at {{ $labels.persistentvolumeclaim }} PVC'\n    - alert: UnderReplicatedPartitions\n      expr: kafka_server_replicamanager_underreplicatedpartitions > 0\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Kafka under replicated partitions'\n        description: 'There are {{ $value }} under replicated partitions on {{ $labels.kubernetes_pod_name }}'\n    - alert: AbnormalControllerState\n      expr: sum(kafka_controller_kafkacontroller_activecontrollercount) by (strimzi_io_name) != 1\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Kafka abnormal controller state'\n        description: 'There are {{ $value }} active controllers in the cluster'\n    - alert: OfflinePartitions\n      expr: sum(kafka_controller_kafkacontroller_offlinepartitionscount) > 0\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Kafka offline partitions'\n        description: 'One or more partitions have no leader'\n    - alert: UnderMinIsrPartitionCount\n      expr: kafka_server_replicamanager_underminisrpartitioncount > 0\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Kafka under min ISR partitions'\n        description: 'There are {{ $value }} partitions under the min ISR on {{ $labels.kubernetes_pod_name }}'\n    - alert: OfflineLogDirectoryCount\n      expr: kafka_log_logmanager_offlinelogdirectorycount > 0\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Kafka offline log directories'\n        description: 'There are {{ $value }} offline log directories on {{ $labels.kubernetes_pod_name }}'\n    - alert: ScrapeProblem\n      expr: up{kubernetes_namespace!~\"openshift-.+\",kubernetes_pod_name=~\".+-kafka-[0-9]+\"} == 0\n      for: 3m\n      labels:\n        severity: major\n      annotations:\n        summary: 'Prometheus unable to scrape metrics from {{ $labels.kubernetes_pod_name }}/{{ $labels.instance }}'\n        description: 'Prometheus was unable to scrape metrics from {{ $labels.kubernetes_pod_name }}/{{ $labels.instance }} for more than 3 minutes'\n    - alert: ClusterOperatorContainerDown\n      expr: count((container_last_seen{container=\"strimzi-cluster-operator\"} > (time() - 90))) < 1 or absent(container_last_seen{container=\"strimzi-cluster-operator\"})\n      for: 1m\n      labels:\n        severity: major\n      annotations:\n        summary: 'Cluster Operator down'\n        description: 'The Cluster Operator has been down for longer than 90 seconds'\n    - alert: KafkaBrokerContainersDown\n      expr: absent(container_last_seen{container=\"kafka\",pod=~\".+-kafka-[0-9]+\"})\n      for: 3m\n      labels:\n        severity: major\n      annotations:\n        summary: 'All `kafka` containers down or in CrashLookBackOff status'\n        description: 'All `kafka` containers have been down or in CrashLookBackOff status for 3 minutes'\n    - alert: KafkaContainerRestartedInTheLast5Minutes\n      expr: count(count_over_time(container_last_seen{container=\"kafka\"}[5m])) > 2 * count(container_last_seen{container=\"kafka\",pod=~\".+-kafka-[0-9]+\"})\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: 'One or more Kafka containers restarted too often'\n        description: 'One or more Kafka containers were restarted too often within the last 5 minutes'\n  - name: entityOperator\n    rules:\n    - alert: TopicOperatorContainerDown\n      expr: absent(container_last_seen{container=\"topic-operator\",pod=~\".+-entity-operator-.+\"})\n      for: 3m\n      labels:\n        severity: major\n      annotations:\n        summary: 'Container topic-operator in Entity Operator pod down or in CrashLookBackOff status'\n        description: 'Container topic-operator in Entity Operator pod has been or in CrashLookBackOff status for 3 minutes'\n    - alert: UserOperatorContainerDown\n      expr: absent(container_last_seen{container=\"user-operator\",pod=~\".+-entity-operator-.+\"})\n      for: 3m\n      labels:\n        severity: major\n      annotations:\n        summary: 'Container user-operator in Entity Operator pod down or in CrashLookBackOff status'\n        description: 'Container user-operator in Entity Operator pod have been down or in CrashLookBackOff status for 3 minutes'\n  - name: connect\n    rules:\n    - alert: ConnectContainersDown\n      expr: absent(container_last_seen{container=~\".+-connect\",pod=~\".+-connect-.+\"})\n      for: 3m\n      labels:\n        severity: major\n      annotations:\n        summary: 'All Kafka Connect containers down or in CrashLookBackOff status'\n        description: 'All Kafka Connect containers have been down or in CrashLookBackOff status for 3 minutes'\n    - alert: ConnectFailedConnector\n      expr: sum(kafka_connect_connector_status{status=\"failed\"}) > 0\n      for: 5m\n      labels:\n        severity: major\n      annotations:\n        summary: 'Kafka Connect Connector Failure'\n        description: 'One or more connectors have been in failed state for 5 minutes,'\n    - alert: ConnectFailedTask\n      expr: sum(kafka_connect_worker_connector_failed_task_count) > 0\n      for: 5m\n      labels:\n        severity: major\n      annotations:\n        summary: 'Kafka Connect Task Failure'\n        description: 'One or more tasks have been in failed state for 5 minutes.'\n  - name: bridge\n    rules:\n    - alert: BridgeContainersDown\n      expr: absent(container_last_seen{container=~\".+-bridge\",pod=~\".+-bridge-.+\"})\n      for: 3m\n      labels:\n        severity: major\n      annotations:\n        summary: 'All Kafka Bridge containers down or in CrashLookBackOff status'\n        description: 'All Kafka Bridge containers have been down or in CrashLookBackOff status for 3 minutes'\n    - alert: AvgProducerLatency\n      expr: strimzi_bridge_kafka_producer_request_latency_avg > 10\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Kafka Bridge producer average request latency'\n        description: 'The average producer request latency is {{ $value }} on {{ $labels.clientId }}'\n    - alert: AvgConsumerFetchLatency\n      expr: strimzi_bridge_kafka_consumer_fetch_latency_avg > 500\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Kafka Bridge consumer average fetch latency'\n        description: 'The average consumer fetch latency is {{ $value }} on {{ $labels.clientId }}'\n    - alert: AvgConsumerCommitLatency\n      expr: strimzi_bridge_kafka_consumer_commit_latency_avg > 200\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Kafka Bridge consumer average commit latency'\n        description: 'The average consumer commit latency is {{ $value }} on {{ $labels.clientId }}'\n    - alert: Http4xxErrorRate\n      expr: strimzi_bridge_http_server_requestCount_total{code=~\"^4..$\", container=~\"^.+-bridge\", path !=\"/favicon.ico\"} > 10\n      for: 1m\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Kafka Bridge returns code 4xx too often'\n        description: 'Kafka Bridge returns code 4xx too much ({{ $value }}) for the path {{ $labels.path }}'\n    - alert: Http5xxErrorRate\n      expr: strimzi_bridge_http_server_requestCount_total{code=~\"^5..$\", container=~\"^.+-bridge\"} > 10\n      for: 1m\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Kafka Bridge returns code 5xx too often'\n        description: 'Kafka Bridge returns code 5xx too much ({{ $value }}) for the path {{ $labels.path }}'\n  - name: mirrorMaker2\n    rules:\n    - alert: MirrorMaker2ContainerDown\n      expr: absent(container_last_seen{container=~\".+-mirrormaker2\",pod=~\".+-mirrormaker2-.+\"})\n      for: 3m\n      labels:\n        severity: major\n      annotations:\n        summary: 'All Kafka Mirror Maker 2 containers down or in CrashLookBackOff status'\n        description: 'All Kafka Mirror Maker 2 containers have been down or in CrashLookBackOff status for 3 minutes'\n  - name: kafkaExporter\n    rules:\n    - alert: UnderReplicatedPartition\n      expr: kafka_topic_partition_under_replicated_partition > 0\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Topic has under-replicated partitions'\n        description: 'Topic  {{ $labels.topic }} has {{ $value }} under-replicated partition {{ $labels.partition }}'\n    - alert: TooLargeConsumerGroupLag\n      expr: kafka_consumergroup_lag > 1000\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Consumer group lag is too big'\n        description: 'Consumer group {{ $labels.consumergroup}} lag is too big ({{ $value }}) on topic {{ $labels.topic }}/partition {{ $labels.partition }}'\n    - alert: NoMessageForTooLong\n      expr: changes(kafka_topic_partition_current_offset[10m]) == 0\n      for: 10s\n      labels:\n        severity: warning\n      annotations:\n        summary: 'No message for 10 minutes'\n        description: 'There is no messages in topic {{ $labels.topic}}/partition {{ $labels.partition }} for 10 minutes'\n  - name: certificates\n    interval: 1m0s\n    rules:\n    - alert: CertificateExpiration\n      expr: |\n        strimzi_certificate_expiration_timestamp_ms/1000 - time() < 30 * 24 * 60 * 60\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: 'Certificate will expire in less than 30 days'\n        description: 'Certificate of type {{ $labels.type }} in cluster {{ $labels.cluster }} in namespace {{ $labels.resource_namespace }} will expire in less than 30 days'\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["patch ",(0,t.jsx)(n.code,{children:"PrometheusRules"})," annotations with escape brackets to avoid helm template conflicts"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"gsed -Ei 's/^([[:space:]]*description:[[:space:]]*)([\"'\\''])(.*)\\2/\\1\"{{\\` \\3 \\`}}\"/' apps-common/strimzi/templates/prometheusrules.yaml\ngsed -Ei 's/^([[:space:]]*summary:[[:space:]]*)([\"'\\''])(.*)\\2/\\1\"{{\\` \\3 \\`}}\"/' apps-common/strimzi/templates/prometheusrules.yaml\n# also manualy remove ` character from annotations\n"})}),"\n",(0,t.jsx)(n.h2,{id:"maintenence",children:"Maintenence"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Backup / Restore"}),"\n",(0,t.jsx)(n.li,{children:"Scaling"}),"\n",(0,t.jsx)(n.li,{children:"Upgrade"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"articles",children:"Articles"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#",children:"Zookeeper vs KRaft"})}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>i});var r=a(6540);const t={},s=r.createContext(t);function o(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);